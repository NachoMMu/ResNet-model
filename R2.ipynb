{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f1981-09ba-4aa2-bf35-fe942fd59a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from typing import Type, Union, List, Optional, Any\n",
    "import copy\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c4c63-b9bd-400d-84b4-a10179824de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb2739-4fb5-479c-9feb-811633fb583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = 'DATABASE/Validación (RESNET 3)/Perfiles rotados/'\n",
    "val_vft_path = 'DATABASE/Validación (RESNET 3)/vft values/vft_values.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94064bea-4ea2-496c-bb25-24b183008d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, vft, transform=None):\n",
    "        '''\n",
    "        data : train data path\n",
    "        vft : train vft path (csv file)\n",
    "        '''\n",
    "        self.train_data = data\n",
    "        self.train_vft = pd.read_csv(vft)\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.profiles = self.train_vft.iloc[:, 0]\n",
    "        self.velocities = self.train_vft.iloc[:, 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_vft)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        profile = self.profiles[index]\n",
    "        velocity = self.velocities[index]\n",
    "        img = Image.open(os.path.join(self.train_data, profile))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return (img, velocity, profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b1a28-c286-42a3-816b-7f1a7a665aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6b955-ce81-452c-9fc5-46b5683c55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = CustomDataset(val_path,val_vft_path,transform)\n",
    "VAL_SIZE = len(val_dataset)\n",
    "print(VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c03e52-b396-4554-8b19-7f3e7f776066",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa818c-5d71-4b43-b27e-298a64d268c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, vft_values, names= next(iter(val_loader))\n",
    "print(vft_values[1], names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278627b0-b950-4268-86c9-35c81005b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Definir la arquitectura de ResNet con bloque Bottleneck\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block: Type[Bottleneck], layers: List[int], num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 32\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=5, stride=2, padding=2, bias=False) \n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 32, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "            #layers.append(nn.Dropout(p=0.3))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019eb085-ac2e-4a22-843d-5fec188eb527",
   "metadata": {},
   "source": [
    "## Cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dcd8a7-1aba-47c9-a36f-26c1fbdbc38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = 'Redes/resnet7.pth'\n",
    "resnet4= ResNet(block=Bottleneck, layers=[2, 2, 2, 2], num_classes=1)\n",
    "resnet4.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6ba2d5-82d2-427a-9229-13814948cfd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_batch2(images, vft_values, values, names,image_path):\n",
    "    batch_size = len(images)\n",
    "    num_rows = 4\n",
    "    num_cols = 4\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            index = i * num_cols + j\n",
    "            if index >= batch_size:\n",
    "                break\n",
    "            image = images[index,0]\n",
    "            vft_value = vft_values[index].item()\n",
    "            value = values[index] \n",
    "            name = names[index]\n",
    "            axes[i][j].imshow(image, cmap='gray')\n",
    "            axes[i][j].set_title(f'vsini: {vft_value} [km/s]', fontsize=6)  \n",
    "            axes[i][j].axis('off')\n",
    "            axes[i][j].text(0.45, 0.98, f'vsini real: {value} [km/s]', color='red', transform=axes[i][j].transAxes, ha='center',fontsize=6)\n",
    "            axes[i][j].text(0.5, 1.15, f'{name}', color='black', transform=axes[i][j].transAxes, ha='center',fontsize=6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefe933-162d-4f59-a637-4f3247dc4d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm  \n",
    "\n",
    "images_val, vft_values_val, names = next(iter(val_loader))\n",
    "images_val = images_val.to(device, dtype=torch.float32)\n",
    "resnet4 = resnet4.to(device)\n",
    "resnet4.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    scores = resnet4(images_val)\n",
    "images_val = images_val.cpu()\n",
    "scores = scores.cpu()\n",
    "true_values = [float(value.item()) for value in vft_values_val] \n",
    "\n",
    "pbar = tqdm(val_loader, total=len(val_loader))\n",
    "for images_val, vft_values_val, _ in pbar:\n",
    "    images_val = images_val.to(device, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        batch_scores = resnet4(images_val)\n",
    "    images_val = images_val.cpu()\n",
    "    batch_scores = batch_scores.cpu()\n",
    "    batch_values = [float(value.item()) for value in vft_values_val] \n",
    "    true_values.extend(batch_values)\n",
    "    scores = torch.cat((scores, batch_scores))\n",
    "\n",
    "r2 = r2_score(true_values, scores)\n",
    "rmse = mean_squared_error(true_values, scores)\n",
    "errors = [error.item() for tensor_error in [(true - score) for true, score in zip(true_values, scores)] for error in tensor_error]\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649610f5-6b08-4de2-9df6-d2104e4fcbbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(true_values, scores, color='blue')\n",
    "plt.title(f'Comparación entre Valores Reales y Predichos, \\n$R^2$ = {r2:.4f} , RMSE = {rmse:.4f}')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Valores Predichos')\n",
    "m, b = np.polyfit(true_values, scores, 1)\n",
    "plt.plot(true_values, m*true_values + b, color='red')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(true_values, errors, color='blue')\n",
    "plt.title(f'Dispersión del Error en datos de Entrenamiento')\n",
    "plt.xlabel('Velocidad [$km/s$]')\n",
    "plt.ylabel('Error Absoluto')\n",
    "\n",
    "plt.tight_layout()\n",
    "image_path = os.path.join(\"Imagenes/Articulo/Error/\", \"r6_ent.png\")\n",
    "#plt.savefig(image_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a01e6e1-a557-4e6c-b3df-e0555da49705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_error = np.mean(errors)\n",
    "std_deviation = np.std(errors)\n",
    "\n",
    "plt.hist(errors, bins=20, color='blue', edgecolor='black')\n",
    "plt.axvline(mean_error, color='red', linestyle='dashed', linewidth=1, label=f'Media = {mean_error:.2f}')\n",
    "plt.axvline(mean_error + std_deviation, color='green', linestyle='dashed', linewidth=1, label=f'Desviación Estándar = {std_deviation:.2f}')\n",
    "plt.axvline(mean_error - std_deviation, color='green', linestyle='dashed', linewidth=1)\n",
    "plt.xlabel('Error Absoluto')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma de Errores de Predicción en datos de Entrenamiento')\n",
    "plt.legend()\n",
    "image_path = os.path.join(\"Imagenes/Articulo/Error/\", \"Histogram_entr6.png\")\n",
    "#plt.savefig(image_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a1af0-27be-45bd-8595-b3951974144f",
   "metadata": {},
   "source": [
    "1) grafico de dispersion del error, para ambos set de datos(calibracion y validacion),calcular error y luego histograma (20 bars),se debe saber valor medio del error(gaussiano), y desviacion estandar. Grafico error vs velocidad (si esta bien, centro en 0).\n",
    "2) Para datos de entrenamiento, grafico con error(y) vs velocidad (x).\n",
    "3) Pasar graficos a latex (.dat), 1 columna valor real, 2 columna valor predicho (1 ; 2) : Exportar FFT datos nuevos(solo imagen: eje x frec, eje y magnitud), tomar 1 modelo, y calcular 3 velocidades diferentes.\n",
    "4) Probar red en modelos reales (adecuar espectro en mismo formato )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe511e-9094-4b2e-a0d9-27147e2142a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "resnet4 = resnet4.to(device='cuda')\n",
    "resnet4.eval()\n",
    "ruta_carpeta = 'Modelos reales/Ajuste gaussiano/'\n",
    "nombre_archivo = 'HD41117.jpg'\n",
    "ruta_completa = os.path.join(ruta_carpeta, nombre_archivo)\n",
    "imagen = Image.open(ruta_completa)\n",
    "\n",
    "imagen = transform(imagen)\n",
    "imagen = imagen.to(device)\n",
    "resnet4 = resnet4.to(device)\n",
    "with torch.no_grad():\n",
    "    scores = resnet4(imagen.unsqueeze(0)) \n",
    "imagen = imagen.cpu()\n",
    "scores = scores.cpu()\n",
    "scores.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bca8dd-a339-4e87-90b6-24a4b23740e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b179e51-55d3-4992-b92e-ff36e67f6ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59204d-4b32-45cf-b70d-2314246c26a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f249b-022a-4383-a709-7471e48ab386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
